{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import compare_ssim, compare_psnr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- how to compute R dynamically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(10,10).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(y_hat, y):\n",
    "    '''\n",
    "    Both inputs should be of shape:\n",
    "    batch_size x n_channels x height x width\n",
    "    \n",
    "    formula from:\n",
    "    https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio    \n",
    "    '''\n",
    "    \n",
    "    assert y_hat.size() == y.size(), 'Input dimensions must match.'\n",
    "\n",
    "    \n",
    "    R = max(y.max(), y_hat.max()).float()\n",
    "    batch_mse = (y_hat-y).pow(2).float().mean(dim=(1,2,3))\n",
    "    \n",
    "    batch_psnr = 20 * torch.log10(R) - 10 * torch.log10(batch_mse)\n",
    "    \n",
    "    return batch_psnr\n",
    "\n",
    "\n",
    "def interpolation_error(y_hat, y):\n",
    "    '''\n",
    "    Computes pixel-wise RMSE over batches.\n",
    "    Both inputs should be of shape:\n",
    "    batch_size x n_channels x height x width\n",
    "    '''\n",
    "    \n",
    "    assert y_hat.size() == y.size(), 'Input dimensions must match.'\n",
    "    \n",
    "    mse = (y_hat-y).pow(2).mean(dim=(1,2,3))\n",
    "    \n",
    "    return mse.sqrt()\n",
    "\n",
    "\n",
    "def ssim(im1, im2, c1=1., c2=1., c3=1.):\n",
    "    '''\n",
    "    Computes the SSIM for color images.\n",
    "    Both inputs should be of shape:\n",
    "    batch_size x n_channels x height x width\n",
    "    '''\n",
    "    \n",
    "    assert im1.size() == im2.size(), 'Input dimensions must match.'\n",
    "    \n",
    "    im1 = im1.float()\n",
    "    im2 = im2.float()\n",
    "    \n",
    "    # compute image statistics\n",
    "    mu1 = im1.mean(dim=(1,2,3), keepdims=True)\n",
    "    mu2 = im2.mean(dim=(1,2,3), keepdims=True)\n",
    "    sig1 = im1.std(dim=(1,2,3), keepdims=True)\n",
    "    sig2 = im2.std(dim=(1,2,3), keepdims=True)\n",
    "    \n",
    "    \n",
    "    # calculate covariance\n",
    "    e1 = (im1-mu1).view(im1.size(0), -1)\n",
    "    e2 = (im2-mu2).view(im2.size(0), -1)\n",
    "    cov = (e1 * e2).sum(dim=1) / (e1.size(1)-1)\n",
    "    \n",
    "    # remove dimensions\n",
    "    mu1 = mu1.squeeze()\n",
    "    mu2 = mu2.squeeze()\n",
    "    sig1 = sig1.squeeze()\n",
    "    sig2 = sig2.squeeze()\n",
    "    \n",
    "    print(mu1.shape, mu2.shape, e1.shape, e2.shape)\n",
    "    print(sig1.shape, sig2.shape, cov.shape)\n",
    "    \n",
    "    # compute ssim\n",
    "    L = (2 * mu1 * mu2 + c1) / (mu1**2 + mu2**2 + c1)\n",
    "    C = (2 * sig1 * sig2 + c2) / (sig1**2 + sig2**2 + c2)\n",
    "    S = (cov + c3) / (sig1 * sig2 + c3)\n",
    "    \n",
    "    return L * C * S\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # b_psnr = psnr(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16]) torch.Size([16]) torch.Size([16, 6220800]) torch.Size([16, 6220800])\n",
      "torch.Size([16]) torch.Size([16]) torch.Size([16])\n",
      "Wall time: 1.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "s = ssim(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = y_hat.float()\n",
    "im2 = y.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can only calculate the mean of floating types. Got Long instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-248-248f24bfc8ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Can only calculate the mean of floating types. Got Long instead."
     ]
    }
   ],
   "source": [
    "(y_hat-y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = im1.cuda()\n",
    "im2 = im2.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16]) torch.Size([16]) torch.Size([16, 6220800]) torch.Size([16, 6220800])\n",
      "torch.Size([16]) torch.Size([16]) torch.Size([16])\n",
      "Wall time: 6.98 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "s = ssim(im1, im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pred_label_random(dims = (16,3,1080,1920)):\n",
    "    y_hat = torch.randint(low=0, high=256, size=dims)\n",
    "    y     = torch.randint(low=0, high=256, size=dims)\n",
    "    return y_hat, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat, y = create_pred_label_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat /= 255\n",
    "y /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1080, 1920])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "win_size exceeds image extent.  If the input is a multichannel (color) image, set multichannel=True.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-285-1024804df75d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mssims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpsnr_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompare_ssim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultichannel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mpsnrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpsnr_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ruth\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skimage\\measure\\_structural_similarity.py\u001b[0m in \u001b[0;36mcompare_ssim\u001b[1;34m(X, Y, win_size, gradient, data_range, multichannel, gaussian_weights, full, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[0mch_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompare_ssim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgradient\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfull\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m                 \u001b[0mmssim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mch\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mch_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ruth\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skimage\\measure\\_structural_similarity.py\u001b[0m in \u001b[0;36mcompare_ssim\u001b[1;34m(X, Y, win_size, gradient, data_range, multichannel, gaussian_weights, full, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mwin_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         raise ValueError(\n\u001b[1;32m--> 147\u001b[1;33m             \u001b[1;34m\"win_size exceeds image extent.  If the input is a multichannel \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m             \"(color) image, set multichannel=True.\")\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: win_size exceeds image extent.  If the input is a multichannel (color) image, set multichannel=True."
     ]
    }
   ],
   "source": [
    "ssims = []\n",
    "for i in range(y_hat.size(0)):\n",
    "    psnr_score = compare_ssim(y_hat[i].numpy(), y[i].numpy(), multichannel=True)\n",
    "    psnrs.append(psnr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([69.1972, 69.2323, 69.2179, 69.2017, 69.2298, 69.2364, 69.1906, 69.2208,\n",
       "        69.2425, 69.2087, 69.2028, 69.2155, 69.2075, 69.2181, 69.2208, 69.2033],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.array(psnrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21.0664, 21.1015, 21.0871, 21.0709, 21.0990, 21.1056, 21.0598, 21.0900,\n",
       "        21.1117, 21.0779, 21.0720, 21.0847, 21.0767, 21.0873, 21.0900, 21.0725])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psnr(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat /= 255\n",
    "y /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10922.3701, 10929.9268, 10923.8184, 10924.7900, 10928.0312, 10928.7568,\n",
       "        10925.1611, 10926.7646, 10930.7734, 10922.0234, 10927.4365, 10916.8906,\n",
       "        10922.7256, 10924.7266, 10927.9043, 10934.1270])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_hat-y).pow(2).float().mean(dim=(1,2,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
