{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code.sepconvfull import model\n",
    "import dataloader\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import discriminator\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import metrics\n",
    "import numpy as np\n",
    "import hyperopt\n",
    "from hyperopt import hp, space_eval, Trials\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'lr': hp.choice('lr', [1e-5, 1e-4, 5e-4]),\n",
    "    'weight_decay': hp.choice('weight_decay', [0, 1e-4, 5e-4]),\n",
    "    'amsgrad':False,\n",
    "    'loss': 'normal', # or wasserstein,\n",
    "    'input_size': 2 # or 4   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_weights(weights):\n",
    "    w = OrderedDict()\n",
    "    for key in weights:\n",
    "        new_key = 'get_kernel.'+key\n",
    "        w[new_key] = weights[key]\n",
    "        \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # init interpolation model\n",
    "# sepconv = model.SepConvNet(kernel_size=51)\n",
    "\n",
    "# weights = torch.load('code/sepconv/network-l1.pytorch')\n",
    "# weights = convert_weights(weights)\n",
    "\n",
    "# sepconv.load_state_dict(weights)\n",
    "# opt = torch.optim.Adam(sepconv.parameters())\n",
    "\n",
    "# # init discriminator\n",
    "# disc_model = discriminator.Discriminator()\n",
    "\n",
    "# sepconv = sepconv.cuda()\n",
    "# D = disc_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultStore:\n",
    "    \n",
    "    def __init__(self, folds=['train', 'valid'], metrics=['psnr', 'ie', 'loss', 'accuracy'], writer=None):\n",
    "        self.folds = folds\n",
    "        self.metrics = metrics\n",
    "        self.results = dict()\n",
    "        self.writer = writer\n",
    "        \n",
    "        for fold in self.folds:\n",
    "            self.results[fold] = dict()\n",
    "            for metric in self.metrics:\n",
    "                self.results[fold][metric] = defaultdict(list)\n",
    "        \n",
    "    def store(self, fold, epoch, value_dict):\n",
    "        for metric, value in value_dict.items():\n",
    "            if isinstance(value, list):\n",
    "                self.results[fold][metric][epoch].extend(value)\n",
    "            else:\n",
    "                self.results[fold][metric][epoch].append(value)\n",
    "        \n",
    "    def write_tensorboard(self, fold, epoch):\n",
    "        for metric in self.metrics:\n",
    "            mean = np.mean(self.results[fold][metric][epoch])\n",
    "            \n",
    "            self.writer.add_scalar(f'{metric}/{fold}', mean, epoch)\n",
    "            self.writer.add_histogram(f'{metric}/{fold}_hist', np.array(self.results[fold][metric][epoch]), epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    '''Minimize loss on validation set'''\n",
    "    \n",
    "    _, _, resultstore = train(params, n_epochs=5, verbose=False)\n",
    "    \n",
    "    losses = resultstore.results['valid']['loss']\n",
    "    max_epoch = np.max(list(losses.keys()))\n",
    "    validation_loss = np.mean(losses[max_epoch])\n",
    "    \n",
    "    return validation_loss\n",
    "\n",
    "\n",
    "def train(params, n_epochs, verbose=True):\n",
    "    \n",
    "    # init interpolation model\n",
    "    sepconv = model.SepConvNet(kernel_size=51)\n",
    "\n",
    "    weights = torch.load('code/sepconv/network-l1.pytorch')\n",
    "    weights = convert_weights(weights)\n",
    "\n",
    "    sepconv.load_state_dict(weights)\n",
    "    opt = torch.optim.Adam(sepconv.parameters())\n",
    "\n",
    "    # init discriminator\n",
    "    disc_model = discriminator.Discriminator()\n",
    "\n",
    "    sepconv = sepconv.cuda()\n",
    "    D = disc_model.cuda()\n",
    "    \n",
    "    \n",
    "    ds = dataloader.adobe240_dataset()\n",
    "    ds = dataloader.TransformedDataset(ds, crop_size=(128,128))\n",
    "\n",
    "    N_train = int(len(ds) * 0.8)\n",
    "    N_valid = len(ds)-N_train\n",
    "\n",
    "    train, valid = torch.utils.data.random_split(ds, [N_train, N_valid])\n",
    "\n",
    "    train_dl = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True, pin_memory=True)\n",
    "    valid_dl = torch.utils.data.DataLoader(valid, batch_size=4, pin_memory=True)\n",
    "\n",
    "    optimizer_G = torch.optim.Adam(sepconv.parameters(), lr=params['lr'], weight_decay=params['weight_decay'], amsgrad=params['amsgrad'])\n",
    "    optimizer_D = torch.optim.Adam(D.parameters(), lr=params['lr'], weight_decay=params['weight_decay'], amsgrad=params['amsgrad'])\n",
    "    critereon = torch.nn.L1Loss()\n",
    "\n",
    "    # metrics\n",
    "    name = f'{int(time.time())}_{params[\"lr\"]}_{params[\"weight_decay\"]}'\n",
    "    writer = SummaryWriter(f'runs/{name}') #TODO hp\n",
    "    R = ResultStore(writer=writer)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        sepconv.train()\n",
    "        D.train()\n",
    "        for i, ((x1, x2), y) in enumerate(train_dl):\n",
    "            \n",
    "            if verbose:\n",
    "                pb = tqdm(desc=f'{epoch+1}/{n_epochs}', total=len(train_dl))    \n",
    "                \n",
    "            x1 = x1.cuda() / 255.\n",
    "            x2 = x2.cuda() / 255.\n",
    "            y = y.cuda() / 255.\n",
    "\n",
    "            y_hat = sepconv(x1, x2)\n",
    "            l1_loss = critereon(y_hat, y)\n",
    "\n",
    "            loss = l1_loss - D(x1, x2, y_hat).sigmoid().mean()\n",
    "\n",
    "            # compute psnr\n",
    "            y_hat = (y_hat * 255).clamp(0,255)\n",
    "            y = (y * 255).clamp(0,255)\n",
    "\n",
    "            psnr = metrics.psnr(y_hat, y)\n",
    "            ie = metrics.interpolation_error(y_hat, y)\n",
    "            \n",
    "            optimizer_G.zero_grad()\n",
    "            l1_loss.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            # train discriminator\n",
    "            y_hat = y_hat.detach()\n",
    "            \n",
    "            if params['wgan']:\n",
    "                for p in D.parameters():\n",
    "                    p.data.clamp_(-0.01, 0.01)\n",
    "\n",
    "            D_loss = D(x1, x2, y_hat).sigmoid().mean() - D(x1, x2, y).sigmoid().mean()\n",
    "\n",
    "            correct_preds = (D(x1, x2, y_hat).sigmoid().round() == 0).flatten().int().detach().cpu().tolist()\n",
    "            correct_preds.extend((D(x1, x2, y).sigmoid().round() == 1).flatten().int().detach().cpu().tolist())\n",
    "          \n",
    "            R.store('train', epoch, {'loss':loss.item(), 'psnr':psnr, 'ie':ie, 'accuracy':correct_preds})\n",
    "    \n",
    "            optimizer_D.zero_grad()\n",
    "            D_loss.backward()\n",
    "            optimizer_D.step()\n",
    "            \n",
    "            if verbose: pb.update()\n",
    "\n",
    "            if i == 50:\n",
    "                break\n",
    "\n",
    "        # update tensorboard\n",
    "        R.write_tensorboard('train', epoch)\n",
    "\n",
    "\n",
    "        sepconv.eval()\n",
    "        D.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, ((x1, x2), y) in enumerate(valid_dl):\n",
    "                x1 = x1.cuda() / 255.\n",
    "                x2 = x2.cuda() / 255.\n",
    "                y = y.cuda() / 255.\n",
    "\n",
    "                y_hat = sepconv(x1, x2)        \n",
    "                l1_loss = critereon(y_hat, y)        \n",
    "                loss = l1_loss - D(x1, x2, y_hat).sigmoid().mean()\n",
    "\n",
    "                # compute psnr\n",
    "                y_hat = (y_hat * 255).clamp(0,255)\n",
    "                y = (y * 255).clamp(0,255)\n",
    "\n",
    "                psnr = metrics.psnr(y_hat, y)\n",
    "                ie = metrics.interpolation_error(y_hat, y)\n",
    "                \n",
    "                y_hat = y_hat.detach()\n",
    "                D_loss = D(x1, x2, y_hat).sigmoid().mean() - D(x1, x2, y).sigmoid().mean()\n",
    "\n",
    "                correct_preds = (D(x1, x2, y_hat).sigmoid().round() == 0).flatten().int().detach().cpu().tolist()\n",
    "                correct_preds.extend((D(x1, x2, y).sigmoid().round() == 1).flatten().int().detach().cpu().tolist())\n",
    "\n",
    "                R.store('valid', epoch, {'loss':loss.item(), 'psnr':psnr, 'ie':ie, 'accuracy':correct_preds})\n",
    "\n",
    "                if i == 50:\n",
    "                    break\n",
    "\n",
    "        # update tensorboard\n",
    "        R.write_tensorboard('valid', epoch)\n",
    "        \n",
    "    # save models\n",
    "    return sepconv, D, R\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 10/10 [40:55<00:00, 243.67s/it, best loss: -0.9863524857689353]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hp = hyperopt.fmin(\n",
    "    fn=objective, \n",
    "    space=params,\n",
    "    algo=hyperopt.tpe.suggest,\n",
    "    trials = trials,\n",
    "    max_evals=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amsgrad': False,\n",
       " 'input_size': 2,\n",
       " 'loss': 'normal',\n",
       " 'lr': 0.0001,\n",
       " 'weight_decay': 0.0005}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space_eval(params, best_hp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
