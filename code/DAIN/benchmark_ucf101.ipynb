{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import numpy\n",
    "import networks\n",
    "# from my_args import  args\n",
    "# from scipy.misc import imread, imsave\n",
    "from imageio import imread\n",
    "from PIL import Image\n",
    "\n",
    "from AverageMeter import  *\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from skimage.measure import compare_ssim\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.filter_size = 4\n",
    "        self.time_step = 0.5\n",
    "        self.channels = 3\n",
    "        self.netName = 'DAIN'\n",
    "        self.use_cuda = True\n",
    "        \n",
    "        self.save_which = 1\n",
    "        self.dtype = torch.cuda.FloatTensor\n",
    "        \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = networks.__dict__[args.netName](    channel=args.channels,\n",
    "                                    filter_size = args.filter_size ,\n",
    "                                    timestep=args.time_step,\n",
    "                                    training=False)\n",
    "\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING CUDA\n"
     ]
    }
   ],
   "source": [
    "if args.use_cuda:\n",
    "    print('USING CUDA')\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.SAVED_MODEL = '../../models/dain/best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../UCF-101/CliffDiving\\\\v_CliffDiving_g17_c04.avi'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##random_triplet():\n",
    "import random\n",
    "folder = random.choice(os.listdir('../../UCF-101/'))\n",
    "files = os.listdir(os.path.join('../../UCF-101/', folder))\n",
    "\n",
    "file = random.choice(files)\n",
    "filepath = os.path.join('../../UCF-101/', folder, file)\n",
    "\n",
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_video():\n",
    "    folder = random.choice(os.listdir('../../UCF-101/'))\n",
    "    files = os.listdir(os.path.join('../../UCF-101/', folder))\n",
    "\n",
    "    file = random.choice(files)\n",
    "    filepath = os.path.join('../../UCF-101/', folder, file)\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = get_random_video()\n",
    "\n",
    "def get_random_triplet(filepath):\n",
    "    cap = cv2.VideoCapture(filepath)\n",
    "    n_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    \n",
    "    frame_start = np.random.randint(n_frames-2)\n",
    "    \n",
    "    frames = []\n",
    "    for index in range(frame_start, frame_start+3):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, index)\n",
    "        _, frame = cap.read()\n",
    "        frames.append(frame)\n",
    "        \n",
    "    return frames\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def triplet_generator(n=1000):\n",
    "    for i in tqdm(range(n)):\n",
    "        filepath = get_random_video()\n",
    "        yield get_random_triplet(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing model weight is: ../../models/dain/best.pth\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(args.SAVED_MODEL):\n",
    "    print(\"The testing model weight is: \" + args.SAVED_MODEL)\n",
    "    if not args.use_cuda:\n",
    "        pretrained_dict = torch.load(args.SAVED_MODEL, map_location=lambda storage, loc: storage)\n",
    "        # model.load_state_dict(torch.load(args.SAVED_MODEL, map_location=lambda storage, loc: storage))\n",
    "    else:\n",
    "        pretrained_dict = torch.load(args.SAVED_MODEL)\n",
    "        # model.load_state_dict(torch.load(args.SAVED_MODEL))\n",
    "\n",
    "    model_dict = model.state_dict()\n",
    "    # 1. filter out unnecessary keys\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "    # 2. overwrite entries in the existing state dict\n",
    "    model_dict.update(pretrained_dict)\n",
    "    # 3. load the new state dict\n",
    "    model.load_state_dict(model_dict)\n",
    "    # 4. release the pretrained dict for saving memory\n",
    "    pretrained_dict = []\n",
    "else:\n",
    "    print(\"*****************************************************************\")\n",
    "    print(\"**** We don't load any trained weights **************************\")\n",
    "    print(\"*****************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda=args.use_cuda\n",
    "save_which=args.save_which\n",
    "dtype = args.dtype\n",
    "unique_id =str(random.randint(0, 100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding(intWidth, intHeight, channel):\n",
    "    \n",
    "    if intWidth != ((intWidth >> 7) << 7):\n",
    "        intWidth_pad = (((intWidth >> 7) + 1) << 7)  # more than necessary\n",
    "        intPaddingLeft =int(( intWidth_pad - intWidth)/2)\n",
    "        intPaddingRight = intWidth_pad - intWidth - intPaddingLeft\n",
    "    else:\n",
    "        intWidth_pad = intWidth\n",
    "        intPaddingLeft = 32\n",
    "        intPaddingRight= 32\n",
    "\n",
    "    if intHeight != ((intHeight >> 7) << 7):\n",
    "        intHeight_pad = (((intHeight >> 7) + 1) << 7)  # more than necessary\n",
    "        intPaddingTop = int((intHeight_pad - intHeight) / 2)\n",
    "        intPaddingBottom = intHeight_pad - intHeight - intPaddingTop\n",
    "    else:\n",
    "        intHeight_pad = intHeight\n",
    "        intPaddingTop = 32\n",
    "        intPaddingBottom = 32\n",
    "    \n",
    "    \n",
    "    return intPaddingLeft, intPaddingRight , intPaddingTop, intPaddingBottom\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_image(im):\n",
    "    X = torch.from_numpy( np.transpose(im, (2,0,1)).astype('float32')/255.0).type(dtype)\n",
    "    \n",
    "    intWidth = X.size(2)\n",
    "    intHeight = X.size(1)\n",
    "    channel = X.size(0)\n",
    "    \n",
    "    \n",
    "    intPaddingLeft, intPaddingRight , intPaddingTop, intPaddingBottom = get_padding(intWidth, intHeight, channel)\n",
    "    \n",
    "    pader = torch.nn.ReplicationPad2d([intPaddingLeft, intPaddingRight , intPaddingTop, intPaddingBottom])\n",
    "    \n",
    "    torch.set_grad_enabled(False)\n",
    "    X = Variable(torch.unsqueeze(X,0))\n",
    "    X = pader(X)\n",
    "    \n",
    "    return X, (intPaddingLeft, intPaddingRight , intPaddingTop, intPaddingBottom)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "def interpolate(im1, im2):\n",
    "    X0, pad_0 = preprocess_image(im1)\n",
    "    X1, pad_1 = preprocess_image(im2)\n",
    "    \n",
    "    y_ = torch.FloatTensor()\n",
    "\n",
    "    assert pad_0 == pad_1\n",
    "    \n",
    "    intPaddingLeft, intPaddingRight , intPaddingTop, intPaddingBottom = pad_0\n",
    "    \n",
    "    if use_cuda:\n",
    "        X0 = X0.cuda()\n",
    "        X1 = X1.cuda()\n",
    "        \n",
    "    y_s,offset,filter = model(torch.stack((X0, X1),dim = 0))\n",
    "    y_ = y_s[save_which]\n",
    "    \n",
    "    \n",
    "    if use_cuda:\n",
    "        X0 = X0.data.cpu().numpy()\n",
    "        if not isinstance(y_, list):\n",
    "            y_ = y_.data.cpu().numpy()\n",
    "        else:\n",
    "            y_ = [item.data.cpu().numpy() for item in y_]\n",
    "        offset = [offset_i.data.cpu().numpy() for offset_i in offset]\n",
    "        filter = [filter_i.data.cpu().numpy() for filter_i in filter]  if filter[0] is not None else None\n",
    "        X1 = X1.data.cpu().numpy()\n",
    "    else:\n",
    "        X0 = X0.data.numpy()\n",
    "        if not isinstance(y_, list):\n",
    "            y_ = y_.data.numpy()\n",
    "        else:\n",
    "            y_ = [item.data.numpy() for item in y_]\n",
    "        offset = [offset_i.data.numpy() for offset_i in offset]\n",
    "        filter = [filter_i.data.numpy() for filter_i in filter]\n",
    "        X1 = X1.data.numpy()\n",
    "        \n",
    "    X0 = np.transpose(255.0 * X0.clip(0,1.0)[0, :, intPaddingTop:intPaddingTop+intHeight, intPaddingLeft: intPaddingLeft+intWidth], (1, 2, 0))\n",
    "\n",
    "\n",
    "    y_ = [np.transpose(255.0 * item.clip(0,1.0)[:, intPaddingTop:intPaddingTop+intHeight, intPaddingLeft: intPaddingLeft+intWidth], (1, 2, 0)) for item in y_]\n",
    "\n",
    "\n",
    "    offset = [np.transpose(offset_i[0, :, intPaddingTop:intPaddingTop+intHeight, intPaddingLeft: intPaddingLeft+intWidth], (1, 2, 0)) for offset_i in offset]\n",
    "    filter = [np.transpose(\n",
    "        filter_i[0, :, intPaddingTop:intPaddingTop + intHeight, intPaddingLeft: intPaddingLeft + intWidth],\n",
    "        (1, 2, 0)) for filter_i in filter]  if filter is not None else None\n",
    "    X1 = np.transpose(255.0 * X1.clip(0,1.0)[0, :, intPaddingTop:intPaddingTop+intHeight, intPaddingLeft: intPaddingLeft+intWidth], (1, 2, 0))\n",
    "    \n",
    "    return y_[0]\n",
    "    \n",
    "    \n",
    "def interpolate_old(im1, im2):\n",
    "    X0 = torch.from_numpy( np.transpose(im1, (2,0,1)).astype('float32')/255.0).type(dtype)\n",
    "    X1 = torch.from_numpy( np.transpose(im2, (2,0,1)).astype('float32')/255.0).type(dtype)\n",
    "\n",
    "    y_ = torch.FloatTensor()\n",
    "\n",
    "    assert (X0.size(1) == X1.size(1))\n",
    "    assert (X0.size(2) == X1.size(2))\n",
    "    \n",
    "    intWidth = X0.size(2)\n",
    "    intHeight = X0.size(1)\n",
    "    channel = X0.size(0)\n",
    "\n",
    "    if intWidth != ((intWidth >> 7) << 7):\n",
    "        intWidth_pad = (((intWidth >> 7) + 1) << 7)  # more than necessary\n",
    "        intPaddingLeft =int(( intWidth_pad - intWidth)/2)\n",
    "        intPaddingRight = intWidth_pad - intWidth - intPaddingLeft\n",
    "    else:\n",
    "        intWidth_pad = intWidth\n",
    "        intPaddingLeft = 32\n",
    "        intPaddingRight= 32\n",
    "\n",
    "    if intHeight != ((intHeight >> 7) << 7):\n",
    "        intHeight_pad = (((intHeight >> 7) + 1) << 7)  # more than necessary\n",
    "        intPaddingTop = int((intHeight_pad - intHeight) / 2)\n",
    "        intPaddingBottom = intHeight_pad - intHeight - intPaddingTop\n",
    "    else:\n",
    "        intHeight_pad = intHeight\n",
    "        intPaddingTop = 32\n",
    "        intPaddingBottom = 32\n",
    "\n",
    "    pader = torch.nn.ReplicationPad2d([intPaddingLeft, intPaddingRight , intPaddingTop, intPaddingBottom])\n",
    "    \n",
    "    torch.set_grad_enabled(False)\n",
    "    X0 = Variable(torch.unsqueeze(X0,0))\n",
    "    X1 = Variable(torch.unsqueeze(X1,0))\n",
    "    X0 = pader(X0)\n",
    "    X1 = pader(X1)\n",
    "    \n",
    "    \n",
    "    if use_cuda:\n",
    "        X0 = X0.cuda()\n",
    "        X1 = X1.cuda()\n",
    "    model.eval()\n",
    "    y_s,offset,filter = model(torch.stack((X0, X1),dim = 0))\n",
    "    y_ = y_s[save_which]\n",
    "    \n",
    "    \n",
    "    if use_cuda:\n",
    "        X0 = X0.data.cpu().numpy()\n",
    "        if not isinstance(y_, list):\n",
    "            y_ = y_.data.cpu().numpy()\n",
    "        else:\n",
    "            y_ = [item.data.cpu().numpy() for item in y_]\n",
    "        offset = [offset_i.data.cpu().numpy() for offset_i in offset]\n",
    "        filter = [filter_i.data.cpu().numpy() for filter_i in filter]  if filter[0] is not None else None\n",
    "        X1 = X1.data.cpu().numpy()\n",
    "    else:\n",
    "        X0 = X0.data.numpy()\n",
    "        if not isinstance(y_, list):\n",
    "            y_ = y_.data.numpy()\n",
    "        else:\n",
    "            y_ = [item.data.numpy() for item in y_]\n",
    "        offset = [offset_i.data.numpy() for offset_i in offset]\n",
    "        filter = [filter_i.data.numpy() for filter_i in filter]\n",
    "        X1 = X1.data.numpy()\n",
    "        \n",
    "    X0 = np.transpose(255.0 * X0.clip(0,1.0)[0, :, intPaddingTop:intPaddingTop+intHeight, intPaddingLeft: intPaddingLeft+intWidth], (1, 2, 0))\n",
    "\n",
    "\n",
    "    y_ = [np.transpose(255.0 * item.clip(0,1.0)[:, intPaddingTop:intPaddingTop+intHeight, intPaddingLeft: intPaddingLeft+intWidth], (1, 2, 0)) for item in y_]\n",
    "    # 0 weggehaald als index\n",
    "\n",
    "    offset = [np.transpose(offset_i[0, :, intPaddingTop:intPaddingTop+intHeight, intPaddingLeft: intPaddingLeft+intWidth], (1, 2, 0)) for offset_i in offset]\n",
    "    filter = [np.transpose(\n",
    "        filter_i[0, :, intPaddingTop:intPaddingTop + intHeight, intPaddingLeft: intPaddingLeft + intWidth],\n",
    "        (1, 2, 0)) for filter_i in filter]  if filter is not None else None\n",
    "    X1 = np.transpose(255.0 * X1.clip(0,1.0)[0, :, intPaddingTop:intPaddingTop+intHeight, intPaddingLeft: intPaddingLeft+intWidth], (1, 2, 0))\n",
    "    del X0; del X1\n",
    "    return y_[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sx = ndimage.sobel(imagei, axis=0, mode='constant')\n",
    "sy = ndimage.sobel(imagei, axis=1, mode='constant')\n",
    "Nabla_x = np.stack([sx,sy])\n",
    "# imagei\n",
    "ssq = np.power(Nabla_x, 2).sum()\n",
    "\n",
    "def im_grad(image):\n",
    "    sx = ndimage.sobel(image, axis=0, mode='constant')\n",
    "    sy = ndimage.sobel(image, axis=1, mode='constant')\n",
    "    nabla = np.stack([sx,sy])\n",
    "    return nabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25552333000.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 240, 320, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nabla_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(y_hat, y):\n",
    "    mse = np.mean((y_hat-y)**2)\n",
    "    R = np.max([y_hat, y])\n",
    "    return 10 * np.log10(R**2 / mse)\n",
    "\n",
    "\n",
    "def ssim(y_hat, y):\n",
    "    None\n",
    "    \n",
    "def ie(y_hat, y):\n",
    "    return np.sqrt(np.mean((y_hat-y)**2))\n",
    "\n",
    "def nie(y_hat, y, eps=1.0):\n",
    "    diff = np.power(y_hat-y, 2)\n",
    "    norm = (im_grad(y)**2).sum()\n",
    "    \n",
    "    return np.sqrt(np.mean(diff/(norm+eps)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.908239"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ie(interpolated, imagei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = triplet_generator(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:37<00:00,  2.76it/s]\n"
     ]
    }
   ],
   "source": [
    "model = model.eval()\n",
    "psnrs = []\n",
    "ssims = []\n",
    "for image1, imagei, image2 in gen:\n",
    "    \n",
    "    imagei = imagei.astype('float32')\n",
    "\n",
    "    interpolated= interpolate_old(image1, image2)\n",
    "    \n",
    "    psnr_score = psnr(interpolated, imagei)\n",
    "    \n",
    "    ssim_score = compare_ssim(interpolated, imagei, multichannel=True)\n",
    "    psnrs.append(psnr_score)\n",
    "    ssims.append(ssim_score)\n",
    "#     print(psnr_score, ssim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33.37709865794216, 0.8417291325258767)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(psnrs), np.mean(ssims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32.18444912304881, 0.8188654567170967)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(psnrs), np.mean(ssims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
